//! Transcoder for articles generated by the LLM.
//!
//! The LLM generates articles with a special format, for example it uses XML to denote code blocks
//! instead of regular Markdown code blocks. This module both decodes this format into markdown
//! components, and encodes them back.

use std::{borrow::Cow, collections::HashMap, mem};

use anyhow::{Context, Result};
use comrak::nodes::{NodeHtmlBlock, NodeValue};
use lazy_regex::regex;
use regex::Regex;
use serde::Deserialize;
use tiktoken_rs::CoreBPE;

/// Decode an article.
///
/// If successful, this returns `body`.
pub fn decode(llm_message: &str) -> String {
    let sanitized = sanitize(llm_message);
    let markdown = xml_for_each(&sanitized, |code| xml_to_markdown(code).ok());

    // The `comrak` crate has a very unusual API which makes this logic difficult to follow. It
    // favours arena allocation instead of a tree-based AST, and requires `Write`rs to regenerate
    // markdown output.
    //
    // There are quirks to the parsing logic, comments have been added for clarity.

    let arena = comrak::Arena::new();
    let mut options = comrak::ComrakOptions::default();
    options.extension.footnotes = true;

    // We don't have an easy built-in way to generate a string with `comrak`, so we encapsulate
    // that logic here.
    let comrak_to_string = |node| {
        let mut out = Vec::<u8>::new();
        comrak::format_commonmark(node, &options, &mut out).unwrap();
        String::from_utf8_lossy(&out)
            .trim()
            .replace("\n\n<!-- end list -->", "")
    };

    let root = comrak::parse_document(&arena, &markdown, &options);

    for block in root.children() {
        offset_embedded_link_ranges(block, -1);
    }

    comrak_to_string(root)
}

/// Offset line ranges in embedded links by a specific value.
///
/// This can be used to offset lines by one, either positively or negatively.
fn offset_embedded_link_ranges<'a>(element: &'a comrak::nodes::AstNode<'a>, offset: i32) -> bool {
    // We have to convert links to use 0-based indexes as the model works with 1-based indexes.
    //
    // TODO: We can update the model so that it works with 0-based indexes, and remove this
    // altogether.

    match &mut element.data.borrow_mut().value {
        NodeValue::Link(link) => {
            let url = mem::take(&mut link.url);
            link.url = url
                .split_once('#')
                .and_then(|(url, anchor)| {
                    if let Some((start, end)) = anchor.split_once('-') {
                        if !start.starts_with('L') || !end.starts_with('L') {
                            return None;
                        }

                        let start = start.get(1..)?.parse::<usize>().ok()?;
                        let end = end.get(1..)?.parse::<usize>().ok()?;

                        Some(format!(
                            "{url}#L{}-L{}",
                            start as i32 + offset,
                            end as i32 + offset,
                        ))
                    } else {
                        if !anchor.starts_with('L') {
                            return None;
                        }

                        let line = anchor.get(1..)?.parse::<usize>().ok()?;
                        Some(format!("{url}#L{}", line as i32 + offset))
                    }
                })
                .unwrap_or(url);

            true
        }

        // False positive lint, we want the side effects:
        // https://github.com/rust-lang/rust-clippy/issues/3351
        #[allow(clippy::unnecessary_fold)]
        _ => element
            .children()
            .map(|child| offset_embedded_link_ranges(child, offset))
            .fold(false, |a, e| a || e),
    }
}

pub fn encode(markdown: &str) -> String {
    let arena = comrak::Arena::new();
    let mut options = comrak::ComrakOptions::default();
    options.extension.footnotes = true;

    let root = comrak::parse_document(&arena, markdown, &options);

    for block in root.children() {
        offset_embedded_link_ranges(block, 1);

        let (info, literal) = match &mut block.data.borrow_mut().value {
            NodeValue::CodeBlock(block) => (block.info.clone(), block.literal.clone()),
            _ => continue,
        };

        let attributes = info
            .split(',')
            .filter_map(|param| {
                let mut iter = param.trim().split(':');

                let key = iter.next()?;
                let value = iter.next()?;

                Some((key.to_owned(), value.to_owned()))
            })
            .collect::<HashMap<String, String>>();

        let xml = attributes.get("type").and_then(|ty| match ty.as_str() {
            "Quoted" => {
                let path = attributes.get("path")?;
                let lang = attributes.get("lang")?;
                let mut lines = attributes.get("lines")?.split('-');

                let start_line = lines.next()?.parse::<usize>().ok()? + 1;
                let end_line = lines.next()?.parse::<usize>().ok()? + 1;

                Some(format!(
                    "<QuotedCode>\n\
                    <Code>\n\
                    {literal}\
                    </Code>\n\
                    <Language>{lang}</Language>\n\
                    <Path>{path}</Path>\n\
                    <StartLine>{start_line}</StartLine>\n\
                    <EndLine>{end_line}</EndLine>\n\
                    </QuotedCode>"
                ))
            }

            "Generated" => {
                let lang = attributes.get("lang")?;

                Some(format!(
                    "<GeneratedCode>\n\
                    <Code>\n\
                    {literal}\
                    </Code>\n\
                    <Language>{lang}</Language>\n\
                    </GeneratedCode>"
                ))
            }

            _ => None,
        });

        if let Some(xml) = xml {
            block.data.borrow_mut().value = NodeValue::HtmlBlock(NodeHtmlBlock {
                literal: xml,
                // The block type here is not used.
                block_type: 0,
            });
        }
    }

    let mut out = Vec::<u8>::new();
    comrak::format_commonmark(root, &options, &mut out).unwrap();
    String::from_utf8_lossy(&out).trim().to_owned()
}

pub fn encode_summarized(markdown: &str, model: &str) -> Result<String> {
    let article = xml_for_each(&encode(markdown), |xml| try_trim_code_xml(xml).ok());
    let bpe = tiktoken_rs::get_bpe_from_model(model)?;
    Ok(limit_tokens(&article, bpe, 500).to_owned())
}

fn sanitize(article: &str) -> String {
    let sanitized = xml_for_each(article, |code| Some(fixup_xml_code(code).into_owned()));
    regex!("<!--.*?-->").replace_all(&sanitized, "").into()
}

fn fixup_xml_code(xml: &str) -> Cow<str> {
    if !xml.trim().starts_with('<') {
        return Cow::Borrowed(xml);
    }

    if let Some(match_) = regex!("<(Generated|Quoted)Code>\\s*<Code>(.*)"sm)
        .captures(xml)
        .and_then(|cap| cap.get(2))
    {
        let mut buf = String::new();

        buf += &xml[..match_.start()];

        // First, we clean up incorrectly escaped symbols in the code block.
        {
            let s = &xml[match_.range()];

            let code_len = regex!("</Code>")
                .find(s)
                .map(|m| m.start())
                .unwrap_or(s.len());
            let (s, tail) = s.split_at(code_len);

            // The `regex` crate does not support negative lookahead, so we cannot write a regex
            // like `&(?!amp;)`. So, we just perform naive substitutions to first obtain an
            // unescaped copy of the string, and then re-escape it in order to fix up the result.
            //
            // This matters if the input string is something like `&amp;foo < &bar&lt;i32&gt;()`:
            //
            // - First, we convert that to `&foo < &bar<i32>()`
            // - Second, we convert it to `&amp;foo < &amp;bar&lt;i32&gt;`, our desired result.

            let s = regex!("&lt;"m).replace_all(s, "<");
            let s = regex!("&gt;"m).replace_all(&s, ">");
            let s = regex!("&amp;"m).replace_all(&s, "&");

            let s = regex!("&"m).replace_all(&s, "&amp;");
            let s = regex!("<"m).replace_all(&s, "&lt;");
            let s = regex!(">"m).replace_all(&s, "&gt;");

            buf += &s;
            buf += tail;
        }

        {
            // Next, we clean up the tags.
            //
            // Because the LLM is generating XML output token-by-token, we may end up in a
            // situation where closing tags are missing, or tags are half written. To fix this,
            // first we remove all half-complete opening or closing tags (e.g. `<foo` or `</`).
            // Then, we add missing closing tags, *in the order we expect them to appear in the
            // final XML output.* This is not perfect, but it should work well enough to allow us
            // to parse the XML.

            buf = regex!("<[^>]*$").replace_all(&buf, "").into_owned();

            for tag in [
                "Code",
                "Language",
                "Path",
                "StartLine",
                "EndLine",
                "QuotedCode",
                "GeneratedCode",
            ] {
                let opening_tag = format!("<{tag}>");
                let closing_tag = format!("</{tag}>");

                if buf.contains(&opening_tag) && !buf.contains(&closing_tag) {
                    buf += &closing_tag;
                }
            }
        }

        Cow::Owned(buf)
    } else {
        Cow::Borrowed(xml)
    }
}

fn xml_to_markdown(xml: &str) -> Result<String> {
    let code_chunk =
        quick_xml::de::from_str::<CodeChunk>(xml).context("failed to deserialize code chunk")?;

    Ok(code_chunk.to_markdown())
}

/// An XML code chunk that is generated by the LLM.
#[derive(serde::Deserialize, Debug)]
enum CodeChunk {
    QuotedCode {
        #[serde(default, rename = "Code")]
        code: String,
        #[serde(default, rename = "Language")]
        language: String,
        #[serde(default, rename = "Path")]
        path: String,
        #[serde(default, rename = "StartLine", deserialize_with = "deserialize_lineno")]
        start_line: Option<u32>,
        #[serde(default, rename = "EndLine", deserialize_with = "deserialize_lineno")]
        end_line: Option<u32>,
    },
    GeneratedCode {
        #[serde(default, rename = "Code")]
        code: String,
        #[serde(default, rename = "Language")]
        language: String,
    },
}

fn deserialize_lineno<'a, D: serde::Deserializer<'a>>(de: D) -> Result<Option<u32>, D::Error> {
    let opt = Option::deserialize(de)?;
    let opt = opt.and_then(|s: String| {
        if s.is_empty() {
            Some(0)
        } else {
            s.parse().ok()
        }
    });

    Ok(opt)
}

impl CodeChunk {
    fn to_markdown(&self) -> String {
        let (ty, code, lang, path, start, end) = match self {
            CodeChunk::QuotedCode {
                code,
                language,
                path,
                start_line,
                end_line,
            } => (
                "Quoted",
                code,
                language,
                path.as_str(),
                start_line.map(|n| n.saturating_sub(1)),
                end_line.map(|n| n.saturating_sub(1)),
            ),
            CodeChunk::GeneratedCode { code, language } => {
                ("Generated", code, language, "", None, None)
            }
        };

        // If we find ticks in the code content, we make sure we have at least N+1 ticks for our
        // braces, to ensure a proper block is formed.
        let ticks = if let Some(captures) = regex!("^(````*)"m).captures(code) {
            let num_ticks = captures.get(1).unwrap().len();
            "`".repeat(num_ticks + 1)
        } else {
            "```".to_owned()
        };

        format!(
            "{ticks}type:{ty},lang:{lang},path:{path},lines:{}-{}\n{code}\n{ticks}",
            start.unwrap_or(0),
            end.unwrap_or(0)
        )
    }
}

/// Modify every XML section of a markdown document.
///
/// The provided closure returns an option, which returns `Some(..)` with a replacement for the
/// input string, or `None` if the input string does not need to be replaced.
///
/// This function operates heuristically, in order to allow malformed XML and XML that contains
/// multiple serial newlines. This means we accept invalid markdown, and are more forgiving with
/// the input, at the expense of creating parsing edge cases that can cause trouble due to input
/// ambiguity.
///
/// One such case is this:
///
/// ```xml
/// This is a sample markdown document. **Hello** world.
///
/// <Code>
///     println!("code ends with </Code>");
/// </Code>
/// ```
///
/// The above markdown document contains an XML block enclosed in `<Code>...</Code>`, but it is
/// not valid as the code snippet contains unescaped characters. Of note, the `println!` call
/// contains literal `<` and `>` characters, which in valid XML *must* be escaped as `&lt;` and
/// `&gt;`, respectively. Because of this, the xml block will be incorrectly parsed to terminate
/// halfway through the string literal provided in the code sample.
///
/// In general, there is no great way around this. We tolerate *most* ambiguity, but this edge case
/// remains as a consequence of ambiguous input.
///
/// For further context, we must accept ambiguous unescaped (invalid) input, as the LLM may
/// generate such documents.
fn xml_for_each(article: &str, f: impl Fn(&str) -> Option<String>) -> String {
    let mut out = String::new();
    let mut rest = article;

    while let Some(captures) = regex!(r"\n(```.*\n)?\s*(<(\w+)>)").captures(rest) {
        let md_block_start = captures.get(1);
        let tag = captures.get(2).unwrap();
        let name = &rest[captures.get(3).unwrap().range()];

        let start = md_block_start.map(|c| c.start()).unwrap_or(tag.start());

        out += &rest[..start];

        let xml = if let Some(captures) = Regex::new(&format!(r"(</{name}>)(?:\n?```)?"))
            .unwrap()
            .captures(rest)
        {
            let m = captures.get(0).unwrap();
            let end_tag = captures.get(1).unwrap();

            let xml = &rest[tag.start()..end_tag.end()];
            rest = &rest[m.end()..];

            xml
        } else {
            let xml = &rest[tag.start()..];
            rest = "";
            xml
        };

        if let Some(update) = f(xml) {
            out += &update;
        } else {
            out += xml;
        }
    }

    out += rest;
    out
}

fn try_trim_code_xml(xml: &str) -> Result<String> {
    // We just remove code chunks completely.

    let xml = fixup_xml_code(xml);
    let _code_chunk: CodeChunk =
        quick_xml::de::from_str(&xml).context("couldn't parse as XML code block")?;
    Ok(String::new())
}

pub fn limit_tokens(text: &str, bpe: CoreBPE, max_tokens: usize) -> &str {
    let mut tokens = bpe.encode_ordinary(text);
    tokens.truncate(max_tokens);

    while !tokens.is_empty() {
        if let Ok(s) = bpe.decode(tokens.clone()) {
            return &text[..s.len()];
        }

        let _ = tokens.pop();
    }

    ""
}

#[cfg(test)]
mod tests {
    use pretty_assertions::assert_eq;

    use super::*;

    #[test]
    fn test_trim_code() {
        let input = "Sample Markdown test.

<QuotedCode>
<Code>
fn foo() -> i32 {
    42
}
</Code>
<Language>Rust</Language>
<Path>src/main.rs</Path>
<StartLine>10</StartLine>
<EndLine>12</EndLine>
</QuotedCode>

<GeneratedCode>
<Code>
fn foo() -> i32 {
    42
}
</Code>
<Language>Rust</Language>
</GeneratedCode>

test
test
test";

        let expected = "Sample Markdown test.





test
test
test";

        let out = xml_for_each(input, |code| try_trim_code_xml(code).ok());

        assert_eq!(expected, out);
    }

    #[test]
    fn test_trim_code_with_regular_xml() {
        let input = "Sample Markdown test.

<p>hello</p>

<QuotedCode>
<Code>
fn foo() -> i32 {
    42
}
</Code>
<Language>Rust</Language>
<Path>src/main.rs</Path>
<StartLine>10</StartLine>
<EndLine>12</EndLine>
</QuotedCode>

<GeneratedCode>
<Code>
fn foo() -> i32 {
    42
}
</Code>
<Language>Rust</Language>
</GeneratedCode>

test
test
test";

        let expected = "Sample Markdown test.

<p>hello</p>





test
test
test";

        let out = xml_for_each(input, |code| try_trim_code_xml(code).ok());

        assert_eq!(expected, out);
    }

    #[test]
    fn test_fixup_quoted_code() {
        let input = "<QuotedCode>
<Code>
fn foo<T>(t: T) -> bool {
    &amp;foo < &bar&lt;i32&gt;(t)
}
</Code>
<Language>Rust</Language>
<Path>src/main.rs</Path>
<StartLine>10</StartLine>
<EndLine>12</EndLine>
</QuotedCode>";

        let expected = "<QuotedCode>
<Code>
fn foo&lt;T&gt;(t: T) -&gt; bool {
    &amp;foo &lt; &amp;bar&lt;i32&gt;(t)
}
</Code>
<Language>Rust</Language>
<Path>src/main.rs</Path>
<StartLine>10</StartLine>
<EndLine>12</EndLine>
</QuotedCode>";

        assert_eq!(expected, &fixup_xml_code(input));
    }

    #[test]
    fn test_fixup_generated_code() {
        let input = "<GeneratedCode>
<Code>
fn foo<T>(t: T) -> bool {
    &amp;foo < &bar&lt;i32&gt;(t)
}
</Code>
<Language>Rust</Language>
</GeneratedCode>";

        let expected = "<GeneratedCode>
<Code>
fn foo&lt;T&gt;(t: T) -&gt; bool {
    &amp;foo &lt; &amp;bar&lt;i32&gt;(t)
}
</Code>
<Language>Rust</Language>
</GeneratedCode>";

        assert_eq!(expected, &fixup_xml_code(input));
    }

    #[test]
    fn test_sanitize_article() {
        let input = "First, we test some *generated code* below:

<GeneratedCode>
<Code>
fn foo<T>(t: T) -> bool {
    &amp;foo < &bar&lt;i32&gt;(t)
}
</Code>
<Language>Rust</Language>
</GeneratedCode>

Then, we test some quoted code:

<QuotedCode>
<Code>
fn foo<T>(t: T) -> bool {
    &amp;foo < &bar&lt;i32&gt;(t)
}
</Code>
<Language>Rust</Language>
<Path>src/main.rs</Path>
<StartLine>10</StartLine>
<EndLine>12</EndLine>
</QuotedCode>

# Foo

These should result in sanitized XML output, while maintaining the rest of the markdown article.
";

        let expected = "First, we test some *generated code* below:

<GeneratedCode>
<Code>
fn foo&lt;T&gt;(t: T) -&gt; bool {
    &amp;foo &lt; &amp;bar&lt;i32&gt;(t)
}
</Code>
<Language>Rust</Language>
</GeneratedCode>

Then, we test some quoted code:

<QuotedCode>
<Code>
fn foo&lt;T&gt;(t: T) -&gt; bool {
    &amp;foo &lt; &amp;bar&lt;i32&gt;(t)
}
</Code>
<Language>Rust</Language>
<Path>src/main.rs</Path>
<StartLine>10</StartLine>
<EndLine>12</EndLine>
</QuotedCode>

# Foo

These should result in sanitized XML output, while maintaining the rest of the markdown article.
";

        assert_eq!(expected, sanitize(input));
    }

    #[test]
    fn test_sanitize_article_partial_generation() {
        let input = "First, we test some **partially** *generated code* below:

<GeneratedCode>
<Code>
fn foo<T>(t: T) -> bool {
    &amp;foo <
";

        let expected = "First, we test some **partially** *generated code* below:

<GeneratedCode>
<Code>
fn foo&lt;T&gt;(t: T) -&gt; bool {
    &amp;foo &lt;
</Code></GeneratedCode>";

        assert_eq!(expected, sanitize(input));
    }

    #[test]
    fn test_decode_2() {
        let input = "First, we test some *generated code* below:

<GeneratedCode>
<Code>
fn foo&lt;T&gt;(t: T) -&gt; bool {
    &amp;foo &lt; &amp;bar&lt;i32&gt;(t)
}
</Code>
<Language>Rust</Language>
</GeneratedCode>

Then, we test some quoted code:

<QuotedCode>
<Code>
fn foo&lt;T&gt;(t: T) -&gt; bool {
    &amp;foo &lt; &amp;bar&lt;i32&gt;(t)
}
</Code>
<Language>Rust</Language>
<Path>src/main.rs</Path>
<StartLine>10</StartLine>
<EndLine>12</EndLine>
</QuotedCode>

# Foo

These should result in base64-encoded XML output, while maintaining the rest of the markdown article.";

        let expected = "First, we test some *generated code* below:

``` type:Generated,lang:Rust,path:,lines:0-0
fn foo<T>(t: T) -> bool {
    &foo < &bar<i32>(t)
}
```

Then, we test some quoted code:

``` type:Quoted,lang:Rust,path:src/main.rs,lines:9-11
fn foo<T>(t: T) -> bool {
    &foo < &bar<i32>(t)
}
```

# Foo

These should result in base64-encoded XML output, while maintaining the rest of the markdown article.";

        let body = decode(input);
        assert_eq!(expected, body);
    }

    #[test]
    fn test_decode_partial_xml() {
        let input = "The `Compiler` struct in [`server/bleep/src/query/compiler.rs`](server/bleep/src/query/compiler.rs) is used to compile a list of queries into a single Tantivy query that matches any of them. Here is an example of its usage:

<QuotedCode>
<Code>
let mut compiler = Compiler::new();
compiler.literal(schema.name, |q| q.repo.clone());
let compiled_query = compiler.compile(queries, tantivy_index);
</Code>
<Language>Rust</Language>
<Path>server/bleep/s
";

        let expected = "The `Compiler` struct in [`server/bleep/src/query/compiler.rs`](server/bleep/src/query/compiler.rs) is used to compile a list of queries into a single Tantivy query that matches any of them. Here is an example of its usage:

``` type:Quoted,lang:Rust,path:server/bleep/s,lines:0-0
let mut compiler = Compiler::new();
compiler.literal(schema.name, |q| q.repo.clone());
let compiled_query = compiler.compile(queries, tantivy_index);
```";

        let body = decode(input);
        assert_eq!(expected, body);
    }

    #[test]
    fn test_decode_partial_xml_no_path() {
        let input = "## Example of Using the Query Compiler

The `Compiler` struct in [`server/bleep/src/query/compiler.rs`](server/bleep/src/query/compiler.rs) is used to compile a list of queries into a single Tantivy query that matches any of them. Here is an example of its usage:

<QuotedCode>
<Code>
let mut compiler = Compiler::new();
compiler.literal(schema.name, |q| q.repo.clone());
let compiled_query = compiler.compile(queries, tantivy_index);
</Code>
<Language>Rust</Language>
</QuotedCode>
";

        let expected = "## Example of Using the Query Compiler

The `Compiler` struct in [`server/bleep/src/query/compiler.rs`](server/bleep/src/query/compiler.rs) is used to compile a list of queries into a single Tantivy query that matches any of them. Here is an example of its usage:

``` type:Quoted,lang:Rust,path:,lines:0-0
let mut compiler = Compiler::new();
compiler.literal(schema.name, |q| q.repo.clone());
let compiled_query = compiler.compile(queries, tantivy_index);
```";

        let body = decode(input);
        assert_eq!(expected, body);
    }

    #[test]
    fn test_sanitize_multi_blocks() {
        let input = "## Example of Using the Query Compiler

The `Compiler` struct in [`server/bleep/src/query/compiler.rs`](server/bleep/src/query/compiler.rs) is used to compile a list of queries into a single Tantivy query that matches any of them. Here is an example of its usage:

<QuotedCode>
<Code>
let mut compiler = Compiler::new();

compiler.literal(schema.name, |q| q.repo.clone());
let compiled_query =
";

        let expected = "## Example of Using the Query Compiler

The `Compiler` struct in [`server/bleep/src/query/compiler.rs`](server/bleep/src/query/compiler.rs) is used to compile a list of queries into a single Tantivy query that matches any of them. Here is an example of its usage:

``` type:Quoted,lang:,path:,lines:0-0
let mut compiler = Compiler::new();

compiler.literal(schema.name, |q| q.repo.clone());
let compiled_query =
```";

        let body = decode(input);
        assert_eq!(expected, body);
    }

    #[test]
    fn test_decode_partial_xml_empty_line_number() {
        let input = "## Example of Using the Query Compiler

The `Compiler` struct in [`server/bleep/src/query/compiler.rs`](server/bleep/src/query/compiler.rs) is used to compile a list of queries into a single Tantivy query that matches any of them. Here is an example of its usage:

<QuotedCode>
<Code>
let mut compiler = Compiler::new();
compiler.literal(schema.name, |q| q.repo.clone());
let compiled_query = compiler.compile(queries, tantivy_index);
</Code>
<Language>Rust</Language>
<StartLine>";

        let expected = "## Example of Using the Query Compiler

The `Compiler` struct in [`server/bleep/src/query/compiler.rs`](server/bleep/src/query/compiler.rs) is used to compile a list of queries into a single Tantivy query that matches any of them. Here is an example of its usage:

``` type:Quoted,lang:Rust,path:,lines:0-0
let mut compiler = Compiler::new();
compiler.literal(schema.name, |q| q.repo.clone());
let compiled_query = compiler.compile(queries, tantivy_index);
```";

        let body = decode(input);
        assert_eq!(expected, body);
    }

    #[test]
    fn test_encode() {
        let input = "Foo

``` type:Quoted,lang:Rust,path:src/main.rs,lines:0-2
fn main() {
    println!(\"hello world\");
}
```

Bar.

``` type:Generated,lang:Rust,path:,lines:0-0
fn main() {
    println!(\"hello world\");
}
```

";

        let expected = "Foo

<QuotedCode>
<Code>
fn main() {
    println!(\"hello world\");
}
</Code>
<Language>Rust</Language>
<Path>src/main.rs</Path>
<StartLine>1</StartLine>
<EndLine>3</EndLine>
</QuotedCode>

Bar.

<GeneratedCode>
<Code>
fn main() {
    println!(\"hello world\");
}
</Code>
<Language>Rust</Language>
</GeneratedCode>";

        let encoded = encode(input);

        assert_eq!(expected, encoded);
    }

    #[test]
    fn test_encode_summarized() {
        let input = "Foo

``` type:Quoted,lang:Rust,path:src/main.rs,lines:0-2
fn main() {
    println!(\"hello world\");
}
```

Bar.

``` type:Generated,lang:Rust,path:,lines:0-0
fn main() {
    println!(\"hello world\");
}
```

";

        let expected = "Foo



Bar.

";

        let encoded = encode_summarized(input, "gpt-4-0613").unwrap();

        assert_eq!(expected, encoded);
    }

    #[test]
    fn test_xml_empty_lines() {
        let input = "
Foo



bar

<GeneratedCode>
<Code>
fn main() {
    let x = 1;

    dbg!(x);
}
</Code>
<Language>Rust</Language>
</GeneratedCode>

quux";

        let expected = "Foo

bar

``` type:Generated,lang:Rust,path:,lines:0-0
fn main() {
    let x = 1;

    dbg!(x);
}
```

quux";

        let body = decode(&sanitize(input));
        assert_eq!(expected, body);
    }

    #[test]
    fn test_limit_tokens() {
        let bpe = tiktoken_rs::get_bpe_from_model("gpt-3.5-turbo").unwrap();
        assert_eq!(limit_tokens("fn 🚨() {}", bpe.clone(), 1), "fn");

        // Note: the following calls return a string that does not split the emoji, despite the
        // tokenizer interpreting the tokens like that.
        assert_eq!(limit_tokens("fn 🚨() {}", bpe.clone(), 2), "fn");
        assert_eq!(limit_tokens("fn 🚨() {}", bpe.clone(), 3), "fn");

        // Now we have a sufficient number of input tokens to overcome the emoji.
        assert_eq!(limit_tokens("fn 🚨() {}", bpe.clone(), 4), "fn 🚨");
        assert_eq!(limit_tokens("fn 🚨() {}", bpe.clone(), 5), "fn 🚨()");
        assert_eq!(limit_tokens("fn 🚨() {}", bpe, 6), "fn 🚨() {}");
    }

    #[test]
    fn test_decode_erroneous_endlist() {
        let input = r#"The code in [`cmd/worker/slack.go`](cmd/worker/slack.go#L1-L42) is a Go program that sends a message to a Slack channel using a webhook URL.

Here's a breakdown of the code:

- Lines 1-8: The package declaration and import statements. The program imports packages for handling bytes, formatting, HTTP requests, and environment variables.

<QuotedCode>
<Code>
package main

import (
    "bytes"
    "fmt"
    "net/http"
    "os"
)
</Code>
<Language>Go</Language>
<Path>cmd/worker/slack.go</Path>
<StartLine>1</StartLine>
<EndLine>8</EndLine>
</QuotedCode>

- Lines 10-12: A constant `SLACK_WEBHOOK_URL` is declared. This constant is used to get the Slack webhook URL from the environment variables.

<QuotedCode>
<Code>
const (
    SLACK_WEBHOOK_URL = "SLACK_WEBHOOK_URL"
)
</Code>
<Language>Go</Language>
<Path>cmd/worker/slack.go</Path>
<StartLine>10</StartLine>
<EndLine>12</EndLine>
</QuotedCode>

- Lines 14-41: The `sendSlackMessage` function is defined. This function takes an organization name as an argument and sends a message to a Slack channel.

<QuotedCode>
<Code>
func sendSlackMessage(org string) error {

    endpoint := os.Getenv(SLACK_WEBHOOK_URL)
    if endpoint == "" {
        return fmt.Errorf("sendSlackMessage: environment variables %s must not be empty",
            SLACK_WEBHOOK_URL)
    }

    orgRelease := fmt.Sprintf("https://github.com/%s/%s/blob/main/%s/release.yaml",
        REPO_OWNER, REPO_ENVS, org)
    message := fmt.Sprintf("New organization %#q added.\nHelmRelease: %s",
        org, orgRelease)

    requestBody := []byte(`{"text": "` + message + `"}`)
    req, err := http.NewRequest("POST", endpoint, bytes.NewBuffer(requestBody))
    if err != nil {
        return fmt.Errorf("sendSlackMessage: failed to create request: %v", err)
    }
    req.Header.Set("Content-Type", "application/json")

    client := &http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        return fmt.Errorf("sendSlackMessage: failed to send Slack message: %v", err)
    }
    defer resp.Body.Close()

    return nil
}
</Code>
<Language>Go</Language>
<Path>cmd/worker/slack.go</Path>
<StartLine>14</StartLine>
<EndLine>41</EndLine>
</QuotedCode>"#;

        let expected_body = r#"The code in [`cmd/worker/slack.go`](cmd/worker/slack.go#L0-L41) is a Go program that sends a message to a Slack channel using a webhook URL.

Here's a breakdown of the code:

- Lines 1-8: The package declaration and import statements. The program imports packages for handling bytes, formatting, HTTP requests, and environment variables.

``` type:Quoted,lang:Go,path:cmd/worker/slack.go,lines:0-7
package main

import (
    "bytes"
    "fmt"
    "net/http"
    "os"
)
```

- Lines 10-12: A constant `SLACK_WEBHOOK_URL` is declared. This constant is used to get the Slack webhook URL from the environment variables.

``` type:Quoted,lang:Go,path:cmd/worker/slack.go,lines:9-11
const (
    SLACK_WEBHOOK_URL = "SLACK_WEBHOOK_URL"
)
```

- Lines 14-41: The `sendSlackMessage` function is defined. This function takes an organization name as an argument and sends a message to a Slack channel.

``` type:Quoted,lang:Go,path:cmd/worker/slack.go,lines:13-40
func sendSlackMessage(org string) error {

    endpoint := os.Getenv(SLACK_WEBHOOK_URL)
    if endpoint == "" {
        return fmt.Errorf("sendSlackMessage: environment variables %s must not be empty",
            SLACK_WEBHOOK_URL)
    }

    orgRelease := fmt.Sprintf("https://github.com/%s/%s/blob/main/%s/release.yaml",
        REPO_OWNER, REPO_ENVS, org)
    message := fmt.Sprintf("New organization %#q added.\nHelmRelease: %s",
        org, orgRelease)

    requestBody := []byte(`{"text": "` + message + `"}`)
    req, err := http.NewRequest("POST", endpoint, bytes.NewBuffer(requestBody))
    if err != nil {
        return fmt.Errorf("sendSlackMessage: failed to create request: %v", err)
    }
    req.Header.Set("Content-Type", "application/json")

    client := &http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        return fmt.Errorf("sendSlackMessage: failed to send Slack message: %v", err)
    }
    defer resp.Body.Close()

    return nil
}
```"#;

        let body = decode(input);
        assert_eq!(expected_body, body);
    }

    #[test]
    fn test_decode_indexing_base() {
        let input = "Foo [bar](bar.rs#L1-L10) [quux](quux.rs#L5).

- Fred [thud](thud.rs#L1-L10) corge.
- Grault [garply](waldo.rs#L1-L10) plugh.";

        let expected = "Foo [bar](bar.rs#L0-L9) [quux](quux.rs#L4).

- Fred [thud](thud.rs#L0-L9) corge.
- Grault [garply](waldo.rs#L0-L9) plugh.";

        let body = decode(input);

        assert_eq!(expected, body);
    }

    #[test]
    fn test_encode_indexing_base() {
        // We test a list with *two* items to check that short circuiting logic doesn't case
        // issues.

        let input = "Foo [bar](bar.rs#L0-L9) [quux](quux.rs#L4).

- Fred [thud](thud.rs#L0-L9) corge.
- Grault [garply](waldo.rs#L0-L9) plugh.";

        let expected = "Foo [bar](bar.rs#L1-L10) [quux](quux.rs#L5).

- Fred [thud](thud.rs#L1-L10) corge.
- Grault [garply](waldo.rs#L1-L10) plugh.";

        assert_eq!(expected, encode(input));
    }

    #[test]
    fn test_bug_short_circuit_link_offset() {
        let input = "Yes, this project is deployable on Kubernetes. The project contains a Helm chart located in the [`helm/bloop/`](helm/bloop/) directory. This chart includes various Kubernetes resource definitions such as:

- A [`Deployment`](helm/bloop/templates/bloop-deployment.yaml#L1-L21) for the main application
- A [`Service`](helm/bloop/templates/bloop-service.yaml#L1-L18) to expose the application within the cluster
- A [`PersistentVolumeClaim`](helm/bloop/templates/bloop-pvc.yaml#L1-L15) for persistent storage
- A [`StatefulSet`](helm/bloop/templates/qdrant-statefulset.yaml#L1-L145) for the Qdrant service
- A [`Job`](helm/bloop/templates/notification-job.yaml#L1-L25) for sending notifications

The Helm chart's configurable values are defined in the [`values.yaml`](helm/bloop/values.yaml#L1-L201) file.";

        let expected_body = "Yes, this project is deployable on Kubernetes. The project contains a Helm chart located in the [`helm/bloop/`](helm/bloop/) directory. This chart includes various Kubernetes resource definitions such as:

- A [`Deployment`](helm/bloop/templates/bloop-deployment.yaml#L0-L20) for the main application
- A [`Service`](helm/bloop/templates/bloop-service.yaml#L0-L17) to expose the application within the cluster
- A [`PersistentVolumeClaim`](helm/bloop/templates/bloop-pvc.yaml#L0-L14) for persistent storage
- A [`StatefulSet`](helm/bloop/templates/qdrant-statefulset.yaml#L0-L144) for the Qdrant service
- A [`Job`](helm/bloop/templates/notification-job.yaml#L0-L24) for sending notifications

The Helm chart's configurable values are defined in the [`values.yaml`](helm/bloop/values.yaml#L0-L200) file.";

        let body = decode(input);
        assert_eq!(expected_body, body);
    }

    #[test]
    fn test_markdown_wrapped_generated_xml_block_info_string() {
        let input = "Generated code, accidentally wrapped in a markdown block:

```jsx
<GeneratedCode>
<Code>
<Link to=\"/home\">Home</Link>
</Code>
<Language>JSX</Language>
</GeneratedCode>
```

Another paragraph.";

        let expected = "Generated code, accidentally wrapped in a markdown block:

``` type:Generated,lang:JSX,path:,lines:0-0
<Link to=\"/home\">Home</Link>
```

Another paragraph.";

        let body = decode(input);
        assert_eq!(expected, body);
    }

    #[test]
    fn test_markdown_wrapped_quoted_xml_block() {
        let input = "Quoted code this time, also accidentally wrapped in a markdown block, but this time without an info string:

```
<QuotedCode>
<Code>
fn main() {
    println!(\"hello world\");
}
</Code>
<Language>Rust</Language>
<Path>src/main.rs</Path>
<StartLine>1</StartLine>
<EndLine>3</EndLine>
</QuotedCode>
```

Another paragraph.";

        let expected = "Quoted code this time, also accidentally wrapped in a markdown block, but this time without an info string:

``` type:Quoted,lang:Rust,path:src/main.rs,lines:0-2
fn main() {
    println!(\"hello world\");
}
```

Another paragraph.";

        let body = decode(input);
        assert_eq!(expected, body);
    }

    #[test]
    fn test_xml_code_with_markdown_doc_comment() {
        let input = "Generated code, with markdown doc comments:

<GeneratedCode>
<Code>
/**
```
assert_eq!(foo(), 123);
```
*/
fn foo() -> i32 {
    123
}
</Code>
<Language>Rust</Language>
</GeneratedCode>

Another paragraph.";

        let expected = "Generated code, with markdown doc comments:

```` type:Generated,lang:Rust,path:,lines:0-0
/**
```
assert_eq!(foo(), 123);
```
*/
fn foo() -> i32 {
    123
}
````

Another paragraph.";

        let body = decode(input);
        assert_eq!(expected, body);
    }

    #[test]
    fn test_xml_code_with_markdown_doc_comment_meta() {
        let input =
            "Generated code, with markdown doc comments that have multiple block nesting levels:

<GeneratedCode>
<Code>
/**
````
```
bar
```
assert_eq!(foo(), 123);
````
*/
fn foo() -> i32 {
    123
}
</Code>
<Language>Rust</Language>
</GeneratedCode>

Another paragraph.";

        let expected =
            "Generated code, with markdown doc comments that have multiple block nesting levels:

````` type:Generated,lang:Rust,path:,lines:0-0
/**
````
```
bar
```
assert_eq!(foo(), 123);
````
*/
fn foo() -> i32 {
    123
}
`````

Another paragraph.";

        let body = decode(input);
        assert_eq!(expected, body);
    }
}
